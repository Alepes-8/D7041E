{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "place all the files from training folder into train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFiles(data, labels, direct):\n",
    "    pathList = os.listdir(direct)\n",
    "    for l in range(len(pathList)):\n",
    "        if \".flac\" in pathList[l]:\n",
    "            data.append(direct + '/' +  pathList[l])\n",
    "        elif \".txt\" in pathList[l]:\n",
    "            labels.append(direct + '/' +  pathList[l])\n",
    "        else:\n",
    "            temp = direct + '/' +  pathList[l]\n",
    "            getFiles(data, labels, temp)\n",
    "    return(data,labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n",
      "33\n",
      "132\n",
      "33\n",
      "Train/Sound/116-288045-0003.flac\n",
      "Test/Sound/1688-142285-0003.flac\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t_data = []\n",
    "t_label = []\n",
    "test_data = []\n",
    "test_label = []\n",
    "\n",
    "train_path = 'Train'\n",
    "test_path = 'Test'\n",
    "\n",
    "t_data, t_label = getFiles(t_data,t_label ,train_path)\n",
    "test_data, test_label = getFiles(test_data,test_label ,test_path)\n",
    "\n",
    "print(len(t_data))\n",
    "print(len(t_label))\n",
    "print(len(test_data))\n",
    "print(len(test_label))\n",
    "\n",
    "print(t_data[3])\n",
    "print(test_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 105\n",
      "7 26\n"
     ]
    }
   ],
   "source": [
    "def spliting(procent, data):\n",
    "    length = len(data)\n",
    "    split = int(np.floor(length*procent))\n",
    "    data1 = data[:split]\n",
    "    data2 = data[split:]\n",
    "    return data1,data2\n",
    "\n",
    "train_data, val_data  = spliting(0.8,t_data)\n",
    "train_label, val_label  = spliting(0.8,t_label)\n",
    "\n",
    "print(len(val_data), len(train_data))\n",
    "print(len(val_label), len(train_label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeArray(array):\n",
    "    array = toDataFrame(array)\n",
    "    array = addColumn(array)\n",
    "    return array\n",
    "    \n",
    "def toDataFrame(array):\n",
    "    array = pd.DataFrame(array)\n",
    "    array = array.rename(columns={0:'file'})\n",
    "    return array\n",
    "\n",
    "def addColumn(array):\n",
    "    speaker = []\n",
    "    for i in range(0, len(array)):\n",
    "        speaker.append(array['file'][i].split('-')[0])\n",
    "        speaker[i] = speaker[i].split('/')[-1]\n",
    "    # We now assign the speaker to a new column \n",
    "    array['speaker'] = speaker\n",
    "    return array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n"
     ]
    }
   ],
   "source": [
    "train_data = changeArray(train_data)\n",
    "train_label= changeArray(train_label)\n",
    "val_data = changeArray(val_data)\n",
    "val_label = changeArray(val_label)\n",
    "test_data = changeArray(test_data)\n",
    "test_label = changeArray(test_label)\n",
    "print(train_data['speaker'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testFiles(files):\n",
    "    # Sets the name to be the path to where the file is in my computer\n",
    "    file_name = str(files.file)\n",
    "    # Loads the audio file as a floating point time series and assigns the default sample rate\n",
    "    # Sample rate is set to 22050 by default\n",
    "    X, sample_rate = librosa.load(file_name, res_type='kaiser_fast')                                #May need to test kaiser_fast\n",
    "    # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    # Computes a chromagram from a waveform or power spectrogram.\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    # Computes spectral contrast\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    # Computes the tonal centroid features (tonnetz)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    return mfccs, chroma, contrast, tonnetz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=815\n",
      "  return f(*args, **kwargs)\n",
      "E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=734\n",
      "  return f(*args, **kwargs)\n",
      "E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=951\n",
      "  return f(*args, **kwargs)\n",
      "E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=710\n",
      "  return f(*args, **kwargs)\n",
      "E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=698\n",
      "  return f(*args, **kwargs)\n",
      "E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=838\n",
      "  return f(*args, **kwargs)\n",
      "E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=879\n",
      "  return f(*args, **kwargs)\n",
      "E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=1022\n",
      "  return f(*args, **kwargs)\n",
      "E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=822\n",
      "  return f(*args, **kwargs)\n",
      "E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=722\n",
      "  return f(*args, **kwargs)\n",
      "E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=865\n",
      "  return f(*args, **kwargs)\n",
      "E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=962\n",
      "  return f(*args, **kwargs)\n",
      "E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=772\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_features= train_data.apply(testFiles, axis =1)\n",
    "val_features=val_data.apply(testFiles, axis =1)\n",
    "test_features= test_data.apply(testFiles, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleLine(data):\n",
    "\n",
    "    feature = []\n",
    "    for i in range(0, len(data)):\n",
    "        feature.append(np.concatenate((\n",
    "            data[i][0],\n",
    "            data[i][1], \n",
    "            data[i][2], \n",
    "            data[i][3],\n",
    "            data[i][4]), axis=0))\n",
    "    array = np.array(feature)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = singleLine(train_features)\n",
    "X_test = singleLine(test_features)\n",
    "X_val = singleLine(val_features)\n",
    "y_train = np.array(train_data['speaker'])\n",
    "y_val = np.array(val_data['speaker'])\n",
    "y_test = np.array(test_data['speaker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hot encoding y\n",
    "lb = LabelEncoder()\n",
    "y_train = to_categorical(lb.fit_transform(y_train))\n",
    "y_val = to_categorical(lb.fit_transform(y_val))\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_val = ss.transform(X_val)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build a simple dense model with early stopping and softmax for categorical classification, remember we have 30 classes\n",
    "model = Sequential()\n",
    "model.add(Dense(193, input_shape=(193,), activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(27, activation = 'softmax'))\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 27) and (None, 7) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17640/728855602.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(X_train, y_train, batch_size=256, epochs=100, \n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     callbacks=[early_stop])\n",
      "\u001b[1;32mE:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"E:\\skola\\code\\New folder\\envs\\ann2test\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 27) and (None, 7) are incompatible\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=256, epochs=100, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17640/3816641502.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Check out our train accuracy and validation accuracy over epochs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Set figure size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Check out our train accuracy and validation accuracy over epochs.\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "# Set figure size.\n",
    "plt.figure(figsize=(12, 8))\n",
    "# Generate line plot of training, testing loss over epochs.\n",
    "plt.plot(train_accuracy, label='Training Accuracy', color='#185fad')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy', color='orange')\n",
    "# Set title\n",
    "plt.title('Training and Validation Accuracy by Epoch', fontsize = 25)\n",
    "plt.xlabel('Epoch', fontsize = 18)\n",
    "plt.ylabel('Categorical Crossentropy', fontsize = 18)\n",
    "plt.xticks(range(0,100,5), range(0,100,5))\n",
    "plt.legend(fontsize = 18)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d41ddcf036e192b8ac36dfbd7c213a6b2f165e8b6cbd963fe422f97219cfe349"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ann2test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
